# Project Proposal
## Artificial Intelligence
### Introduction
The project discussed in this paper aims to demonstrate how artificial intelligence (AI)
can attempt to determine if a news article is real or not. This is a problem we face every day
and furthermore with today’s misinformation, it is crucial to distinguish real news from fake.
The score of this project would be to have a way to differentiate real from fake news with
a good accuracy. I would be using training data from Kaggle dataset, however my testing data
would come from scrapping news sites. This project will contain its scope to constraint
satisfaction, regression training and testing, and state space searching.
### Motivation
This project was inspired by the amount of false information that is now being spread
online. With millions of news websites and platforms, it is becoming extremely difficult to know
if a news article is real or fake. Furthermore, this would help me extend my knowledge of
TfidfVectorizer, which is very useful in measuring the importance of a term/word within a
text/document. Additionally, I would be interested to explore the possibility of implementing this
AI algorithm into a browser addon, for real time news check. However, for the sake of this
project, the score will be limited only to cleaning, training and measuring accuracy.
### Evaluation
If this project satisfies the requirements listed below, it will be deemed successful. It
must first demonstrate a grasp of and application of the AI concepts relevant to its domain. The
second requirement is that it be free of significant bugs, runnable during class, and finished in a
reasonable amount of time. Finally, the solution produced by this project must be acceptable as
“good enough”; i.e. it performs better than a human in terms of our optimization metric. This
optimization metric will measure success based on the volume of real/fake news.
### Approach
For this project, I would first try to fully understand PassiveAggressiveClassifier and
TfidfVectorizer as those would be the driving force behind the scenes. The Kaggle dataset is
well prepared and there are several examples that could be helpful, however my idea is to dive
deep into the data and fine tune the models in order to get the best possible accuracy. I believe
that using real data, scrapped from news websites, would be a very good accuracy test.
However, it might be a bit challenging to pull the data and store it in the proper format, while
manually deciding if the article is real or fake. Visualization of this data would be key for further
understanding the problem of fake news and improving the data model
